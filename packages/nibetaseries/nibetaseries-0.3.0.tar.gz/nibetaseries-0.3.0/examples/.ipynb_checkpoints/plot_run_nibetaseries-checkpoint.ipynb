{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Running NiBetaSeries using ds000164 (Stroop Task)\n",
    "===============================================================\n",
    "\n",
    "This example runs through a basic call of NiBetaSeries using\n",
    "the commandline entry point ``nibs``.\n",
    "While this example is using python, typically ``nibs`` will be\n",
    "called directly on the commandline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages\n",
    "=================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile  # make a temporary directory for files\n",
    "import os  # interact with the filesystem\n",
    "import urllib.request  # grad data from internet\n",
    "import tarfile  # extract files from tar\n",
    "from subprocess import Popen, PIPE, STDOUT  # enable calling commandline\n",
    "\n",
    "import matplotlib.pyplot as plt  # manipulate figures\n",
    "import seaborn as sns  # display results\n",
    "import pandas as pd   # manipulate tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download relevant data from ds000164 (and Atlas Files)\n",
    "======================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our working directory: /tmp/tmpqvhrl3hr\n"
     ]
    }
   ],
   "source": [
    "data_dir = tempfile.mkdtemp()\n",
    "print('Our working directory: {}'.format(data_dir))\n",
    "\n",
    "# download the tar data\n",
    "url = \"https://www.dropbox.com/s/qoqbiya1ou7vi78/ds000164-test_v1.tar.gz?dl=1\"\n",
    "tar_file = os.path.join(data_dir, \"ds000164.tar.gz\")\n",
    "u = urllib.request.urlopen(url)\n",
    "data = u.read()\n",
    "u.close()\n",
    "\n",
    "# write tar data to file\n",
    "with open(tar_file, \"wb\") as f :\n",
    "    f.write(data)\n",
    "\n",
    "# extract the data   \n",
    "tar = tarfile.open(tar_file, mode='r|gz')\n",
    "tar.extractall(path=data_dir)\n",
    "\n",
    "os.remove(tar_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the minimal dataset necessary to run nibs\n",
    "=================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmpqvhrl3hr/\n",
      "    ds000164/\n",
      "        dataset_description.json\n",
      "        task-stroop_bold.json\n",
      "        README\n",
      "        CHANGES\n",
      "        T1w.json\n",
      "        task-stroop_events.json\n",
      "        derivatives/\n",
      "            fmriprep/\n",
      "                sub-001/\n",
      "                    func/\n",
      "                        sub-001_task-stroop_bold_space-MNI152NLin2009cAsym_brainmask.nii.gz\n",
      "                        sub-001_task-stroop_bold_confounds.tsv\n",
      "                        sub-001_task-stroop_bold_space-MNI152NLin2009cAsym_preproc.nii.gz\n",
      "            data/\n",
      "                Schaefer2018_100Parcels_7Networks_order.txt\n",
      "                Schaefer2018_100Parcels_7Networks_order_FSLMNI152_2mm.nii.gz\n",
      "        sub-001/\n",
      "            func/\n",
      "                sub-001_task-stroop_bold.nii.gz\n",
      "                sub-001_task-stroop_events.tsv\n",
      "            anat/\n",
      "                sub-001_T1w.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "\n",
    "\n",
    "list_files(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate events file so it satifies assumptions\n",
    "=================================================\n",
    "1. the correct column has 1's and 0's corresponding to correct and incorrect,\n",
    "respectively.\n",
    "2. the condition column is renamed to trial_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the file\n",
    "-------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    onset  duration correct  condition  response_time\n",
      "0   0.342         1       Y    neutral          1.186\n",
      "1   3.345         1       Y  congruent          0.667\n",
      "2  12.346         1       Y  congruent          0.614\n",
      "3  15.349         1       Y    neutral          0.696\n",
      "4  18.350         1       Y    neutral          0.752\n"
     ]
    }
   ],
   "source": [
    "events_file = os.path.join(data_dir,\n",
    "                           \"ds000164\",\n",
    "                           \"sub-001\",\n",
    "                           \"func\",\n",
    "                           \"sub-001_task-stroop_events.tsv\")\n",
    "events_df = pd.read_csv(events_file, sep='\\t', na_values=\"n/a\")\n",
    "print(events_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the Y/N to 1/0\n",
    "---------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    onset  duration  correct  condition  response_time\n",
      "0   0.342         1        1    neutral          1.186\n",
      "1   3.345         1        1  congruent          0.667\n",
      "2  12.346         1        1  congruent          0.614\n",
      "3  15.349         1        1    neutral          0.696\n",
      "4  18.350         1        1    neutral          0.752\n"
     ]
    }
   ],
   "source": [
    "events_df['correct'].replace({\"Y\": 1, \"N\": 0}, inplace=True)\n",
    "print(events_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace condition with trial_type\n",
    "---------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    onset  duration  correct trial_type  response_time\n",
      "0   0.342         1        1    neutral          1.186\n",
      "1   3.345         1        1  congruent          0.667\n",
      "2  12.346         1        1  congruent          0.614\n",
      "3  15.349         1        1    neutral          0.696\n",
      "4  18.350         1        1    neutral          0.752\n"
     ]
    }
   ],
   "source": [
    "events_df.rename({\"condition\": \"trial_type\"}, axis='columns', inplace=True)\n",
    "print(events_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the file\n",
    "-------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.to_csv(events_file, sep=\"\\t\", na_rep=\"n/a\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manipulate the region order file\n",
    "================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the atlas file\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                   1    2   3    4  5\n",
      "0  1  7Networks_LH_Vis_1  120  18  131  0\n",
      "1  2  7Networks_LH_Vis_2  120  18  132  0\n",
      "2  3  7Networks_LH_Vis_3  120  18  133  0\n",
      "3  4  7Networks_LH_Vis_4  120  18  135  0\n",
      "4  5  7Networks_LH_Vis_5  120  18  136  0\n"
     ]
    }
   ],
   "source": [
    "atlas_txt = os.path.join(data_dir,\n",
    "                         \"ds000164\",\n",
    "                         \"derivatives\",\n",
    "                         \"data\",\n",
    "                         \"Schaefer2018_100Parcels_7Networks_order.txt\")\n",
    "atlas_df = pd.read_csv(atlas_txt, sep=\"\\t\", header=None)\n",
    "print(atlas_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop coordinate columns\n",
    "-----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                   1\n",
      "0  1  7Networks_LH_Vis_1\n",
      "1  2  7Networks_LH_Vis_2\n",
      "2  3  7Networks_LH_Vis_3\n",
      "3  4  7Networks_LH_Vis_4\n",
      "4  5  7Networks_LH_Vis_5\n"
     ]
    }
   ],
   "source": [
    "atlas_df.drop([2, 3, 4, 5], axis='columns', inplace=True)\n",
    "print(atlas_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename columns with the approved headings: \"index\" and \"regions\"\n",
    "----------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             regions\n",
      "0      1  7Networks_LH_Vis_1\n",
      "1      2  7Networks_LH_Vis_2\n",
      "2      3  7Networks_LH_Vis_3\n",
      "3      4  7Networks_LH_Vis_4\n",
      "4      5  7Networks_LH_Vis_5\n"
     ]
    }
   ],
   "source": [
    "atlas_df.rename({0: 'index', 1: 'regions'}, axis='columns', inplace=True)\n",
    "print(atlas_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove prefix \"7Networks\"\n",
    "-------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index   regions\n",
      "0      1  LH_Vis_1\n",
      "1      2  LH_Vis_2\n",
      "2      3  LH_Vis_3\n",
      "3      4  LH_Vis_4\n",
      "4      5  LH_Vis_5\n"
     ]
    }
   ],
   "source": [
    "atlas_df.replace(regex={'7Networks_(.*)': '\\\\1'}, inplace=True)\n",
    "print(atlas_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write out the file as .tsv\n",
    "--------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_tsv = atlas_txt.replace(\".txt\", \".tsv\")\n",
    "atlas_df.to_csv(atlas_tsv, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run nibs\n",
    "========\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'181214-01:04:57,775 nipype.workflow INFO:\\n'\n",
      "b\"\\t Workflow nibetaseries_participant_wf settings: ['check', 'execution', 'logging', 'monitoring']\\n\"\n",
      "b'181214-01:04:57,790 nipype.workflow INFO:\\n'\n",
      "b'\\t Running in parallel.\\n'\n",
      "b'181214-01:04:57,793 nipype.workflow INFO:\\n'\n",
      "b'\\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 10.46/10.46, Free processors: 4/4.\\n'\n",
      "b\"/home/james/.conda/envs/nibetaseries/lib/python3.6/site-packages/grabbit/core.py:448: UserWarning: Domain with name 'bids' already exists; returning existing Domain configuration.\\n\"\n",
      "b'  warnings.warn(msg)\\n'\n",
      "b'181214-01:04:57,867 nipype.workflow INFO:\\n'\n",
      "b'\\t [Node] Setting-up \"nibetaseries_participant_wf.single_subject001_wf.betaseries_wf.betaseries_node\" in \"/tmp/tmpqvhrl3hr/ds000164/derivatives/work/NiBetaSeries_work/nibetaseries_participant_wf/single_subject001_wf/betaseries_wf/3c4aed0ab1086ff3e5564f0c23e59d393e724e58/betaseries_node\".\\n'\n",
      "b'181214-01:04:57,873 nipype.workflow INFO:\\n'\n",
      "b'\\t [Node] Running \"betaseries_node\" (\"nibetaseries.interfaces.nistats.BetaSeries\")\\n'\n",
      "b'181214-01:04:59,797 nipype.workflow INFO:\\n'\n",
      "b'\\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 10.26/10.46, Free processors: 3/4.\\n'\n",
      "b'                     Currently running:\\n'\n",
      "b'                       * nibetaseries_participant_wf.single_subject001_wf.betaseries_wf.betaseries_node\\n'\n",
      "b\"/home/james/.conda/envs/nibetaseries/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\\n\"\n",
      "b'  return f(*args, **kwds)\\n'\n",
      "b'/home/james/.conda/envs/nibetaseries/lib/python3.6/site-packages/nibabel-2.3.0-py3.6.egg/nibabel/nifti1.py:582: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\\n'\n",
      "b'  ext_def = np.fromstring(ext_def, dtype=np.int32)\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b\"/home/james/.conda/envs/nibetaseries/lib/python3.6/site-packages/nistats/hemodynamic_models.py:268: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\\n\"\n",
      "b'  frame_times.max() * (1 + 1. / (n - 1)), n_hr)\\n'\n",
      "b\"/home/james/.conda/envs/nibetaseries/lib/python3.6/site-packages/nistats/hemodynamic_models.py:55: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\\n\"\n",
      "b'  time_stamps = np.linspace(0, time_length, float(time_length) / dt)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 1 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n",
      "b'\\n'\n",
      "b'Computation of 1 runs done in 0 seconds\\n'\n",
      "b'\\n'\n",
      "b'Computing run 1 out of 1 runs (go take a coffee, a big one)\\n'\n"
     ]
    }
   ],
   "source": [
    "out_dir = os.path.join(data_dir, \"ds000164\", \"derivatives\")\n",
    "work_dir = os.path.join(out_dir, \"work\")\n",
    "atlas_mni_file = os.path.join(data_dir,\n",
    "                              \"ds000164\",\n",
    "                              \"derivatives\",\n",
    "                              \"data\",\n",
    "                              \"Schaefer2018_100Parcels_7Networks_order_FSLMNI152_2mm.nii.gz\")\n",
    "cmd = \"\"\"\\\n",
    "nibs -c WhiteMatter CSF \\\n",
    "--participant_label 001 \\\n",
    "-w {work_dir} \\\n",
    "-a {atlas_mni_file} \\\n",
    "-l {atlas_tsv} \\\n",
    "{bids_dir} \\\n",
    "fmriprep \\\n",
    "{out_dir} \\\n",
    "participant\n",
    "\"\"\".format(atlas_mni_file=atlas_mni_file,\n",
    "           atlas_tsv=atlas_tsv,\n",
    "           bids_dir=os.path.join(data_dir, \"ds000164\"),\n",
    "           out_dir=out_dir,\n",
    "           work_dir=work_dir)\n",
    "# call nibs\n",
    "p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT)\n",
    "\n",
    "while True:\n",
    "    line = p.stdout.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe generated outputs\n",
    "=========================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect results\n",
    "===============\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_path = os.path.join(out_dir, \"NiBetaSeries\", \"nibetaseries\", \"sub-001\", \"func\")\n",
    "trial_types = ['congruent', 'incongruent', 'neutral']\n",
    "filename_template = \"sub-001_task-stroop_bold_space-MNI152NLin2009cAsym_preproc_trialtype-{trial_type}_matrix.tsv\"\n",
    "pd_dict = {}\n",
    "for trial_type in trial_types:\n",
    "    file_path = os.path.join(corr_mat_path, filename_template.format(trial_type=trial_type))\n",
    "    pd_dict[trial_type] = pd.read_csv(file_path, sep='\\t', na_values=\"n/a\", index_col=0)\n",
    "# display example matrix\n",
    "pd_dict[trial_type].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the results\n",
    "=================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(10, 30),\n",
    "                         gridspec_kw={'wspace': 0.025, 'hspace': 0.075})\n",
    "\n",
    "cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "r = 0\n",
    "for trial_type, df in pd_dict.items():\n",
    "    g = sns.heatmap(df, ax=axes[r], vmin=-.5, vmax=1., square=True,\n",
    "                    cbar=True, cbar_ax=cbar_ax)\n",
    "    axes[r].set_title(trial_type)\n",
    "    # iterate over rows\n",
    "    r += 1\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
