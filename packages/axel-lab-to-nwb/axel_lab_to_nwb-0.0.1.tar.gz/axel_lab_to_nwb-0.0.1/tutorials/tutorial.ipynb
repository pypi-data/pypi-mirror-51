{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Calcium Imaging data from .mat to NWB file\n",
    "More details on [NWB Calcium imaging data](https://pynwb.readthedocs.io/en/stable/tutorials/domain/ophys.html#calcium-imaging-data).\n",
    "\n",
    "**0.** We start importing the relevant modules to read from .mat file and to manipulate NWB file groups and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from pynwb import NWBFile, NWBHDF5IO, ProcessingModule\n",
    "from pynwb.ophys import TwoPhotonSeries, OpticalChannel, ImageSegmentation, Fluorescence, DfOverF, MotionCorrection\n",
    "from pynwb.device import Device\n",
    "from pynwb.base import TimeSeries\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Load the .mat files containing calcium imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = '/Users/bendichter/Desktop/Axel Lab/data' #r'C:\\Users\\Luiz\\Desktop\\Axel'\n",
    "\n",
    "# Open info file\n",
    "fname0 = 'fly2_run1_info.mat'\n",
    "fpath0 = os.path.join(path_to_files, fname0)\n",
    "f_info = scipy.io.loadmat(fpath0, struct_as_record=False, squeeze_me=True)\n",
    "info = f_info['info']\n",
    "\n",
    "# Open .mat file containing Calcium Imaging data\n",
    "fname1 = '2019_04_18_Nsyb_NLS6s_Su_walk_G_fly2_run1_8401reg.mat'\n",
    "fpath1 = os.path.join(path_to_files, fname1)\n",
    "file = h5py.File(fpath1, 'r')\n",
    "options = file['options']\n",
    "landmarkThreshold = file['landmarkThreshold']\n",
    "templates = file['templates']\n",
    "R = file['R']\n",
    "Y = file['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Create a new [NWB file instance](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile), fill it with all the relevant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new NWB file\n",
    "nwb = NWBFile(session_description='my CaIm recording', \n",
    "              identifier='EXAMPLE_ID', \n",
    "              session_start_time=datetime.now(tzlocal()),\n",
    "              experimenter='Dr. ABC',\n",
    "              lab='My Lab',\n",
    "              institution='My University',\n",
    "              experiment_description='Some description.',\n",
    "              session_id='IDX')\n",
    "print(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Create [Device](https://pynwb.readthedocs.io/en/stable/pynwb.device.html#pynwb.device.Device) and [OpticalChannel](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.OpticalChannel) containers to be used by a specific [ImagingPlane](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.ImagingPlane)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and add device\n",
    "device = Device(info.objective.replace('/','_'))\n",
    "nwb.add_device(device)\n",
    "\n",
    "# Create an Imaging Plane for Yellow\n",
    "optical_channel_Y = OpticalChannel(name='optical_channel_Y',\n",
    "                                   description='2P Optical Channel',\n",
    "                                   emission_lambda=510.)\n",
    "imaging_plane_Y = nwb.create_imaging_plane(name='imaging_plane_Y',\n",
    "                                           optical_channel=optical_channel_Y,\n",
    "                                           description='Imaging plane',\n",
    "                                           device=device,\n",
    "                                           excitation_lambda=488., \n",
    "                                           imaging_rate=info.daq.scanRate,\n",
    "                                           indicator='NLS-GCaMP6s',\n",
    "                                           location='whole central brain')\n",
    "\n",
    "# Create an Imaging Plane for Red\n",
    "optical_channel_R = OpticalChannel(name='optical_channel_R',\n",
    "                                   description='2P Optical Channel',\n",
    "                                   emission_lambda=633.)\n",
    "imaging_plane_R = nwb.create_imaging_plane(name='imaging_plane_R',\n",
    "                                           optical_channel=optical_channel_R,\n",
    "                                           description='Imaging plane',\n",
    "                                           device=device,\n",
    "                                           excitation_lambda=488., \n",
    "                                           imaging_rate=info.daq.scanRate,\n",
    "                                           indicator='redStinger',\n",
    "                                           location='whole central brain')\n",
    "\n",
    "print(nwb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Create a [TwoPhotonSeries](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.TwoPhotonSeries) container to store the raw data. Raw data usually goes on the `acquisition` group of NWB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores raw data in acquisition group - dims=(X,Y,Z,T)\n",
    "raw_image_series_Y = TwoPhotonSeries(name='TwoPhotonSeries_Y', \n",
    "                                     imaging_plane=imaging_plane_Y,\n",
    "                                     rate=info.daq.scanRate,\n",
    "                                     dimension=[36, 167, 257],\n",
    "                                     data=Y[:,:,:,:]) \n",
    "\n",
    "raw_image_series_R = TwoPhotonSeries(name='TwoPhotonSeries_R', \n",
    "                                     imaging_plane=imaging_plane_R,\n",
    "                                     rate=info.daq.scanRate,\n",
    "                                     dimension=[36, 167, 257],\n",
    "                                     data=R[:,:,:,:]) \n",
    "\n",
    "nwb.add_acquisition(raw_image_series_Y)\n",
    "nwb.add_acquisition(raw_image_series_R)\n",
    "\n",
    "print(nwb.acquisition['TwoPhotonSeries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** A very important data preprocessing step for calcium signals is motion correction. We can store the processed result data in the [MotionCorrection](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.MotionCorrection) container, inside the `processing` group of NWB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates ophys ProcessingModule and add to file\n",
    "ophys_module = ProcessingModule(name='ophys',\n",
    "                                description='contains optical physiology processed data.')\n",
    "nwb.add_processing_module(ophys_module)\n",
    "\n",
    "#Stores corrected data in TwoPhotonSeries container\n",
    "corrected_image_series = TwoPhotonSeries(name='TwoPhotonSeries_corrected', \n",
    "                                         imaging_plane=imaging_plane,\n",
    "                                         rate=info.daq.scanRate,\n",
    "                                         dimension=[36, 167, 257],\n",
    "                                         data=Y[:,:,:,0])\n",
    "\n",
    "#TimeSeries XY translation correction values\n",
    "xy_translation = TimeSeries(name='xy_translation', \n",
    "                            data=np.zeros((257,2)),\n",
    "                            rate=info.daq.scanRate)\n",
    "\n",
    "#Adds the corrected image stack to MotionCorrection container\n",
    "motion_correction = MotionCorrection()\n",
    "motion_correction.create_corrected_image_stack(corrected=corrected_image_series, \n",
    "                                               original=raw_image_series, \n",
    "                                               xy_translation=xy_translation)\n",
    "\n",
    "#Add MotionCorrection to processing group\n",
    "ophys_module.add_data_interface(motion_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Any processed data should be stored in the `processing` group of NWB files. A list of available containers can be found [here](https://pynwb.readthedocs.io/en/stable/overview_nwbfile.html#processing-modules). These include, for example, [DfOverF](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.DfOverF), [ImageSegmentation](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.ImageSegmentation), [Fluorescence](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.Fluorescence) and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores processed data of different types in ProcessingModule group\n",
    "#Image segmentation\n",
    "img_seg = ImageSegmentation()\n",
    "ophys_module.add_data_interface(img_seg)\n",
    "\n",
    "#Fluorescence\n",
    "fl = Fluorescence()\n",
    "ophys_module.add_data_interface(fl)\n",
    "\n",
    "#DfOverF\n",
    "dfoverf = DfOverF()\n",
    "ophys_module.add_data_interface(dfoverf)\n",
    "\n",
    "print(nwb.processing['ophys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** The NWB structure is is place, but we still need to save it to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves to NWB file\n",
    "fname_nwb = 'file_1.nwb'\n",
    "fpath_nwb = os.path.join(path_to_files, fname_nwb)\n",
    "with NWBHDF5IO(fpath_nwb, mode='w') as io:\n",
    "    io.write(nwb)\n",
    "print('File saved with size: ', os.stat(fpath_nwb).st_size/1e6, ' mb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Finally, let's load it and check the file contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads NWB file\n",
    "with NWBHDF5IO(fpath_nwb, mode='r') as io:\n",
    "    nwb = io.read()\n",
    "    print(nwb)\n",
    "    print(nwb.processing['ophys'].data_interfaces['MotionCorrection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evan Schaffer data\n",
    "from `.npz` files to NWB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "from pynwb import NWBFile, NWBHDF5IO, ProcessingModule\n",
    "from pynwb.ophys import TwoPhotonSeries, OpticalChannel, ImageSegmentation, Fluorescence, DfOverF, MotionCorrection\n",
    "from pynwb.device import Device\n",
    "from pynwb.base import TimeSeries\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = np.load('2019_07_01_Nsyb_NLS6s_walk_fly2.npz')\n",
    "print('First file:')\n",
    "print('Groups:', a.files)\n",
    "print('Dims (height,width,depth):', a['dims'])\n",
    "print('dFF shape: ', a['dFF'].shape)\n",
    "\n",
    "b = np.load('2019_07_01_Nsyb_NLS6s_walk_fly2_A.npz')\n",
    "print('     ')\n",
    "print('Second file - Sparse Matrix:')\n",
    "print('Groups:', b.files)\n",
    "print('Indices: ', b['indices'], '  | Shape: ',b['indices'].shape)\n",
    "print('Indptr: ', b['indptr'], '  | Shape: ',b['indptr'].shape)\n",
    "print('Format: ', b['format'])\n",
    "print('Shape: ', b['shape'])\n",
    "print('Data: ', b['data'], '  | Shape: ',b['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start creating a new NWB file instance and populating it with fake raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new NWB file\n",
    "nwb = NWBFile(session_description='my CaIm recording', \n",
    "              identifier='EXAMPLE_ID', \n",
    "              session_start_time=datetime.now(tzlocal()),\n",
    "              experimenter='Dr. ABC',\n",
    "              lab='My Lab',\n",
    "              institution='My University',\n",
    "              experiment_description='Some description.',\n",
    "              session_id='IDX')\n",
    "\n",
    "#Create and add device\n",
    "device = Device('MyDevice')\n",
    "nwb.add_device(device)\n",
    "\n",
    "# Create an Imaging Plane for Yellow\n",
    "optical_channel = OpticalChannel(name='optical_channel',\n",
    "                                 description='2P Optical Channel',\n",
    "                                 emission_lambda=510.)\n",
    "imaging_plane = nwb.create_imaging_plane(name='imaging_plane',\n",
    "                                         optical_channel=optical_channel,\n",
    "                                         description='Imaging plane',\n",
    "                                         device=device,\n",
    "                                         excitation_lambda=488., \n",
    "                                         imaging_rate=1000.,\n",
    "                                         indicator='NLS-GCaMP6s',\n",
    "                                         location='whole central brain',\n",
    "                                         conversion=1.0)\n",
    "\n",
    "#Stores raw data in acquisition group - dims=(X,Y,Z,T)\n",
    "Xp = a['dims'][0][0]\n",
    "Yp = a['dims'][0][1]\n",
    "Zp = a['dims'][0][2]\n",
    "T = a['dFF'].shape[1]\n",
    "nCells = a['dFF'].shape[0]\n",
    "fake_data = np.random.randn(Xp,Yp,Zp,100)\n",
    "raw_image_series = TwoPhotonSeries(name='TwoPhotonSeries', \n",
    "                                   imaging_plane=imaging_plane,\n",
    "                                   rate=1000.,\n",
    "                                   dimension=[Xp,Yp,Zp],\n",
    "                                   data=fake_data) \n",
    "nwb.add_acquisition(raw_image_series)\n",
    "\n",
    "#Creates ophys ProcessingModule and add to file\n",
    "ophys_module = ProcessingModule(name='ophys',\n",
    "                                description='contains optical physiology processed data.')\n",
    "nwb.add_processing_module(ophys_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform the lists of indices into (xp,yp,zp) masks. With the masks created, we can add them to a plane segmentation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voxel_mask(indices, dims):\n",
    "    \"\"\"\n",
    "    indices - List with voxels indices, e.g. [64371, 89300, 89301, ..., 3763753, 3763842, 3763843]\n",
    "    dims - (height, width, depth) in pixels\n",
    "    \"\"\"\n",
    "    voxel_mask = []\n",
    "    for ind in indices:\n",
    "        zp = np.floor(ind/(dims[0]*dims[1])).astype('int')\n",
    "        rest = ind%(dims[0]*dims[1])\n",
    "        yp = np.floor(rest/dims[0]).astype('int')\n",
    "        xp = rest%dims[0]\n",
    "        voxel_mask.append((xp,yp,zp,1))\n",
    "    \n",
    "    return voxel_mask \n",
    "        \n",
    "#Call function\n",
    "indices = b['indices']\n",
    "indptr = indices[b['indptr'][0:-1]]\n",
    "dims = np.squeeze(a['dims'])\n",
    "voxel_mask = make_voxel_mask(indptr, dims)\n",
    "\n",
    "#Create Image Segmentation compartment\n",
    "img_seg = ImageSegmentation()\n",
    "ophys_module.add_data_interface(img_seg)\n",
    "\n",
    "#Create plane segmentation and add ROIs\n",
    "ps = img_seg.create_plane_segmentation(description='plane segmentation',\n",
    "                                       imaging_plane=imaging_plane, \n",
    "                                       reference_images=raw_image_series)\n",
    "ps.add_roi(voxel_mask=voxel_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ROIs created, we can add the dF/F data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DFF measures\n",
    "dff = DfOverF(name='dff_interface')\n",
    "ophys_module.add_data_interface(dff)\n",
    "\n",
    "#create ROI regions\n",
    "roi_region = ps.create_roi_table_region(description='ROI table region', \n",
    "                                        region=[0])\n",
    "\n",
    "#create ROI response series\n",
    "dff_data = a['dFF']\n",
    "dFF_series = dff.create_roi_response_series(name='df_over_f',\n",
    "                                            data=dff_data,\n",
    "                                            unit='NA',\n",
    "                                            rois=roi_region,\n",
    "                                            rate=1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains two arrays with pixel indexing: one with all pixels at cells and one with only one reference pixel per cell. Let's see how it looks like in a 3D plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D scatter with masks points\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Reference points\n",
    "xptr = [p[0] for p in voxel_mask]\n",
    "yptr = [p[1] for p in voxel_mask]\n",
    "zptr = [p[2] for p in voxel_mask]\n",
    "\n",
    "#All points in mask\n",
    "all_pt_mask = make_voxel_mask(indices, dims)\n",
    "x = [p[0] for p in all_pt_mask]\n",
    "y = [p[1] for p in all_pt_mask]\n",
    "z = [p[2] for p in all_pt_mask]\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, c='k', marker='.', s=.5)\n",
    "ax.scatter(xptr, yptr, zptr, c='r', marker='o', s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves to NWB file\n",
    "path_to_files = ''\n",
    "fname_nwb = 'file_1.nwb'\n",
    "fpath_nwb = os.path.join(path_to_files, fname_nwb)\n",
    "with NWBHDF5IO(fpath_nwb, mode='w') as io:\n",
    "    io.write(nwb)\n",
    "print('File saved with size: ', os.stat(fpath_nwb).st_size/1e6, ' mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads NWB file\n",
    "with NWBHDF5IO(fpath_nwb, mode='r') as io:\n",
    "    nwb = io.read()\n",
    "    print(nwb)\n",
    "    print(nwb.processing['ophys'].data_interfaces['dff_interface'].roi_response_series['df_over_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
