# `shadho` - Scalable Hardware-Aware Distributed Hyperparameter Optimizer

`shadho` is framework for distributed hyperparameter optimization developed for
machine/deep learning applications.

- Website/Documentation: <https://shadho.readthedocs.io>
- Bug Reports: <https://github.com/jeffkinnison/shadho/issues>

# Installation

**Note:** Installation may look like it hangs, but this is just a behind-the-scenes
build process.

```
$ git clone https://github.com/jeffkinnison/shadho
$ cd shadho
$ pip install .
```

# Dependencies

- numpy
- scipy
- [pyrameter](https://github.com/jeffkinnison/pyrameter)
- [Work Queue](http://ccl.cse.nd.edu/software/workqueue/) (Built and installed by setup.py)
