{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:34.062259Z",
     "start_time": "2019-08-05T12:53:31.332740Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from batchflow import *\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import *\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:36.364114Z",
     "start_time": "2019-08-05T12:53:34.066376Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = MNIST(batch_class=ImagesBatch)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MICROBATCH = None\n",
    "    DEVICE = None\n",
    "\n",
    "print('\\nMicrobatching is: {}'.format(MICROBATCH))\n",
    "print('\\nDevice is: {}'.format(DEVICE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:36.409727Z",
     "start_time": "2019-08-05T12:53:36.366187Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_classification_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': (28, 28, 1),\n",
    "        'inputs/labels/classes': 10,\n",
    "        'initial_block/inputs': 'images',\n",
    "        'loss': 'ce',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "\n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'labels': B('labels')},\n",
    "    }\n",
    "    return pipeline_config\n",
    "\n",
    "def get_segmentation_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': (28, 28, 1),\n",
    "        'inputs/masks/shape': (28, 28, 1),\n",
    "        'initial_block/inputs': 'images',\n",
    "        'body/decoder/blocks/combine_op': 'softsum', # for some reason `concat` is not working from within pytest \n",
    "        'loss': 'mse',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'masks': B('images')},\n",
    "    }\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:36.471423Z",
     "start_time": "2019-08-05T12:53:36.411855Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(pipeline_config):\n",
    "    \"\"\" Pipeline config must contain 'model', 'model_config', 'feed_dict' keys. \"\"\"\n",
    "    pipeline = (Pipeline(config=pipeline_config)\n",
    "                .init_variable('loss_history', [])\n",
    "                .multiply(multiplier=1/255., preserve_type=False)\n",
    "                .to_array()\n",
    "                .init_model('dynamic', C('model'),\n",
    "                            'MODEL', config=C('model_config'))\n",
    "                .train_model('MODEL', fetches='loss',\n",
    "                             feed_dict=C('feed_dict'),\n",
    "                             save_to=V('loss_history', mode='a'))\n",
    "                )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:36.531370Z",
     "start_time": "2019-08-05T12:53:36.478516Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(task, model_class, config, description, batch_size=16, n_iters=10):\n",
    "    if task.startswith('c'):\n",
    "        pipeline_config = get_classification_config(model_class, config)\n",
    "    elif task.startswith('s'):\n",
    "        pipeline_config = get_segmentation_config(model_class, config)\n",
    "        \n",
    "    train_pipeline = get_pipeline(pipeline_config) << mnist.train\n",
    "    _ = train_pipeline.run(batch_size, n_iters=n_iters, bar=True,\n",
    "                           bar_desc=W(V('loss_history')[-1].format('Loss is {:7.7}')))\n",
    "    \n",
    "    print('{} {} is done'.format(task, description))\n",
    "    return train_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:37.790982Z",
     "start_time": "2019-08-05T12:53:36.534239Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'fa'*2,\n",
    "                      'units': [64, 128],},\n",
    "    'body': {'layout': 'fa'*2,\n",
    "             'units': [256, 512]},\n",
    "    'head': {'layout': 'faf',\n",
    "             'units': [600,10]},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TFModel, config, 'simple fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:53:53.833125Z",
     "start_time": "2019-08-05T12:53:37.792791Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'head/layout': 'f'\n",
    "}\n",
    "\n",
    "ppl = run('classification', XceptionS, config, 'Xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "ppl = run('classification', MobileNet_v3_small, config, 'MobileNet_v3_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:54:02.800283Z",
     "start_time": "2019-08-05T12:53:53.839367Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/filters': 4,\n",
    "    'body/encoder': {'num_stages': 3},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', UNet, config, 'unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:54:13.226326Z",
     "start_time": "2019-08-05T12:54:02.805017Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'filters': 2},\n",
    "    'body/encoder': {'base': ResNet18,\n",
    "                     'filters':[4]*4},\n",
    "    'body/embedding': [{'layout': 'cna', 'filters': 16}]*4,\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', EncoderDecoder, config, 'encoder-decoder with ResNet18 backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T12:54:56.500534Z",
     "start_time": "2019-08-05T12:54:13.228707Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'cna', 'filters': 4},\n",
    "    'body/encoder': {'base': ResNet,\n",
    "                     'num_blocks': [2, 2, 2, 2, 2],\n",
    "                     'filters': [2, 4, 8, 16, 32]},\n",
    "    'body/embedding': {'filters': 32},\n",
    "    'body/decoder': {'num_stages': 5,\n",
    "                     'factor': 32,\n",
    "                     'skip': True,\n",
    "                     'upsample': {'layout': 'X'},\n",
    "                     'blocks': {'base': DenseNet.block,\n",
    "                                'num_layers': [2, 2, 2, 2, 2],\n",
    "                                'growth_rate': 2,\n",
    "                                'skip': False}},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', EncoderDecoder, config, 'encoder-decoder with ResNet, DenseNet blocks')\n",
    "\n",
    "config['body/encoder/block/resnext'] = True \n",
    "ppl = run('segmentation', EncoderDecoder, config, 'encoder-decoder with ResNeXt, DenseNet blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
