{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:25.154705Z",
     "start_time": "2019-08-07T13:33:22.563553Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from batchflow import *\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.torch import *\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:26.793516Z",
     "start_time": "2019-08-07T13:33:25.157009Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = MNIST(batch_class=ImagesBatch)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MICROBATCH = None\n",
    "    DEVICE = None\n",
    "\n",
    "print('\\nMicrobatching is: {}'.format(MICROBATCH))\n",
    "print('\\nDevice is: {}'.format(DEVICE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:26.854520Z",
     "start_time": "2019-08-07T13:33:26.798662Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (1, 28, 28)\n",
    "\n",
    "def get_classification_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': IMAGE_SHAPE,\n",
    "        'inputs/labels/classes': 10,\n",
    "        'initial_block/inputs': 'images',\n",
    "        'loss': 'ce',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "\n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'labels': B('labels')},\n",
    "    }\n",
    "    return pipeline_config\n",
    "\n",
    "def get_segmentation_config(model_class, config):\n",
    "    default_config = {\n",
    "        'inputs/images/shape': IMAGE_SHAPE,\n",
    "        'inputs/masks/shape': IMAGE_SHAPE,\n",
    "        'initial_block/inputs': 'images',\n",
    "        'body/decoder/blocks/combine_op': 'concat', # for some reason `concat` is not working from within pytest \n",
    "        'loss': 'mse',\n",
    "        'microbatch': MICROBATCH,\n",
    "        'device': DEVICE,\n",
    "    }\n",
    "    \n",
    "    pipeline_config = {\n",
    "        'model': model_class,\n",
    "        'model_config': {**default_config, **config},\n",
    "        'feed_dict': {'images': B('images'),\n",
    "                      'masks': B('images')},\n",
    "    }\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:26.894306Z",
     "start_time": "2019-08-07T13:33:26.857352Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pipeline(pipeline_config):\n",
    "    \"\"\" Pipeline config must contain 'model', 'model_config', 'feed_dict' keys. \"\"\"\n",
    "    vals = pipeline_config['feed_dict'].values()\n",
    "\n",
    "    pipeline = (Pipeline(config=pipeline_config)\n",
    "                .init_variable('loss_history', [])\n",
    "                .multiply(multiplier=1/255., preserve_type=False)\n",
    "                .to_array(channels='first', dtype='float32')\n",
    "                .init_model('dynamic', C('model'),\n",
    "                            'MODEL', config=C('model_config'))\n",
    "                .train_model('MODEL', *vals,\n",
    "                             fetches='loss',\n",
    "                             save_to=V('loss_history', mode='a'))\n",
    "                )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:26.945067Z",
     "start_time": "2019-08-07T13:33:26.903063Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(task, model_class, config, description, batch_size=16, n_iters=10):\n",
    "    if task.startswith('c'):\n",
    "        pipeline_config = get_classification_config(model_class, config)\n",
    "    elif task.startswith('s'):\n",
    "        pipeline_config = get_segmentation_config(model_class, config)\n",
    "        \n",
    "    train_pipeline = get_pipeline(pipeline_config) << mnist.train\n",
    "    _ = train_pipeline.run(batch_size, n_iters=n_iters, bar=True,\n",
    "                           bar_desc=W(V('loss_history')[-1].format('Loss is {:7.7}')))\n",
    "    \n",
    "    print('{} {} is done'.format(task, description))\n",
    "    return train_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:27.336020Z",
     "start_time": "2019-08-07T13:33:26.948897Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block': {'layout': 'fa'*2,\n",
    "                      'units': [64, 128],},\n",
    "    'body': {'layout': 'fa'*2,\n",
    "             'units': [256, 512]},\n",
    "    'head': {'layout': 'faf',\n",
    "             'units': [600,10]},\n",
    "}\n",
    "\n",
    "ppl = run('classification', TorchModel, config, 'simple fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T13:33:46.434926Z",
     "start_time": "2019-08-07T13:33:27.337821Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'initial_block/filters': 4,\n",
    "    'body/encoder': {'num_stages': 3},\n",
    "}\n",
    "\n",
    "ppl = run('segmentation', UNet, config, 'unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
